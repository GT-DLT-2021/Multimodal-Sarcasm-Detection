{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8803-bert.ipynb","provenance":[],"authorship_tag":"ABX9TyM2Whn0SzChJ17Bu9KFKHer"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uh3IxQmhuXjH","executionInfo":{"status":"ok","timestamp":1637980890833,"user_tz":300,"elapsed":11566,"user":{"displayName":"xiaohao xiaohao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05789524953128221691"}},"outputId":"dcd10374-a5a3-4325-b703-b2084c4cee73"},"source":["import torch\n","!pip install transformers\n","from transformers import AutoModel, AutoTokenizer \n","#from transformers.models.bert.modeling_bert import BertEmbeddings\n","\n","bertweet = AutoModel.from_pretrained(\"vinai/bertweet-large\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-large\")\n","\n","# INPUT TWEET IS ALREADY NORMALIZED!\n","line = \"DHEC confirms HTTPURL via @USER :crying_face:\"\n","\n","input_ids = torch.tensor([tokenizer.encode(line)])\n","\n","with torch.no_grad():\n","    features = bertweet(input_ids)  # Models outputs are now tuples\n","\n","print(features)\n","    \n","## With TensorFlow 2.0+:\n","# from transformers import TFAutoModel\n","# bertweet = TFAutoModel.from_pretrained(\"vinai/bertweet-large\")\n"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at vinai/bertweet-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at vinai/bertweet-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0862,  0.0521, -0.1026,  ...,  0.0147,  0.1891, -0.0736],\n","         [ 0.1007, -0.0159, -0.6580,  ...,  0.1054,  0.2050,  0.0699],\n","         [ 0.2216,  0.0395, -0.5482,  ..., -0.1893,  0.3768,  0.2154],\n","         ...,\n","         [ 0.0523,  0.2308, -0.8912,  ...,  0.3122, -0.0351, -0.0617],\n","         [-0.0252, -0.1803, -0.0527,  ...,  0.3899, -0.1398, -0.2169],\n","         [ 0.0499,  0.0034, -0.1559,  ..., -0.0495,  0.1139, -0.0543]]]), pooler_output=tensor([[ 0.4696, -0.6525,  0.4046,  ...,  0.5129, -0.1899, -0.2950]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"]}]}]}